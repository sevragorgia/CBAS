---
title: Changes in gene expression in a common aquarium sponge under different symbiont
  activity regimes.
author: "Sergio Vargas R."
date: '2016-07-26'
output:
  html_document: default
  pdf_document: default
---
```{r load_libraries, include=FALSE}
library(knitr)
library(ggplot2)
library(reshape2)
library("geneplotter")
library("EDASeq")
library("DESeq2")
library("pheatmap")
library("gplots")

library("RColorBrewer")
library("genefilter")

library("topGO")

library("vegan")

library("BiocParallel")
register(MulticoreParam(4))

```

***
##Preliminary remarks

The common blue aquarium sponge is a cyanosponge commonly found in salt water aquaria. Most aquarium hobbiest refer to it as *Collospongia auris*, however its taxonomic affiliation is not clear. I refer to this sponge as the "Common Blue Aquarium Sponge", **CBAS** in short. CBAS is a cyanosponge, it harbours cyanobacteria from the Candidatus *Synechococcus spongiarum* clade. 

Culture of the sponge under different light conditions resulted in the observation that when kept under dark conditions the sponge bleaches, turning completely white after ca. 12 weeks under darkness; the "normal" color of the sponge varies between green, blue and violet. Changes in color are accompanied by changes in size and general morphology. For instance, the sponges form elongated projections; the normal shape of the sponge is lobated and plate like.

It is not clear whether the cyanobacteria are still present in the bleached sponge tissues. Bioanalyzer profiles of RNA extracts from bleached sponges clearly showed that the samples lack the rRNA bands belonging the cyanobacteria but qPCR experiments pointed towards the presence of cyanobacteria in DNA extracts from sponges exposed to max. 6 weeeks darkeness [^1].  However, this evidence is (in my opinion) not conclusive due to a number of technical problems associated to these experiments; RNA extractions only demonstrate that the symbionts are not active and the qPCR experiments suffered from incosistent amplifying of the samples. Another piece of evidence (weakly) pointing towards this is the capacity of the sponges to regain color after 8-12 weeks re-exposure to light; symbiont uptake from the water column cannot be excluded, however, apparently *S. spongiarum* is not present in the water.  All in all, the evidence at hand point to the presence of the symbionts in some kind of inactive (transcriptionl/metabolic) state in the sponge tissues exposed to dark conditions.

##Study rational

Since it is possible to manipulate the trascriptional/metabolic state of the cyanobacterial symbionts through the exposure of the system to darkness, CBAS represents an interesting system to assess how the sponge reacts to symbiont inactivation. I use RNA-Seq data to *de novo* assemble a reference transcriptome for this system and to assess changes in the sponge gene expression profiles associated with different symbiont transcriptional states. I hope these data contributes to our understanding of the molecular mechanisms used by sponges to interact with their microbiomes.

***

#Introduction


#Materials and Methods

##Sponge culture and experimental setting
Sponges are kept in a 200L salt water aquarium under a 12hr light:12hr darkness regime using two T5 fluorescent lights. For all experiments one large sponge was used and a hole-puncher was used to produce explants of 10 mm diameter [^2]. The explants were place in a recipient with sand and were allow to recover for 3-5 days under control light conditions. Recovery was visually assesed by inspecting the border of the explants to corroborate the tissue healed at the cutting points. After this, the explants were moved to a section of the aquarium covered with a two sheets of black plastic cloth. The plastic cloth serves to block the light from the T5 lights; the amount of light (in klux) penetrating the plastic sheets was ~0 klux while under normal conditions at least ~15 klux can be measured at the water surface. Twelve weeks after moving the sponges to the dark side of the aquarium, the explants were flash-frozen in liquid nitrogen and kept at -80 °C; at this point in time explants kept under control conditions were also sampled. This experiment was repeated several times[^3]; the resulting tissue samples were used to test different RNA extraction protocols and assess whether bleaching can be reproduced in the aquarium.

##RNA extraction, libray preparation and sequencing

Total RNA was extracted using a hybrid protocol that combines a regular CTAB extraction and a spin-column clean-up step. Briefly, using mortar and pestle, samples were pulverized in liquid nitrogen. The tissue powder was lysed in 600 $\mu$L warm (56 °C) CTAB-PVP-NaCl buffer containing $\beta$-mercaptoethanol for 15-20 minutes with agitation (~500 rpm). After lysis, one volume acidic Phenol-Chloroform-Isoamyl alcohol (25:24:1) was added to the samples and the extraction was vigorously agitated until the liquid had a milky appearance. The samples were then centrifuged at 14,000 rpm for 15 minutes to separate the phases. 400 $\mu$L of the polar phase were then transfered to a new 2mL microcentrifuge tube and the nucleic-acids were precipitated for 10 minutes using one volume isopropanol. The nucleic acids were recovered by centrifugation (14,000rpm for 20 minutes at ~16°C) and the recovered pellets were washed twice with 1 mL cold 80% ethanol. After washing, ethanol droplets were removed with a 10 $\mu$L pipette and the pellets were air dried for ~10 minute before resuspending in 30 $\mu$L nuclease-free water.

After this initial extraction, the ZR-Duet DNA/RNA MiniPrep [^4] was used, following the manufacturers recommendations, to separate DNA and RNA from the sample. The RNA was resuspended in 30 $\mu$L nuclease-free water and quality checked initially on 1% agarose gels and finally on a Bioanalyzer 2100 Nano RNA chip. RNA concentration was measured on a Nanodrop 1000. RIN values could be calculated for bleached samples only; control samples have four rRNA peaks corresponding to the 16S, 18S, 23S and 28S rRNA fragments and the Bioanalyzer cannot calculate their RIN value. Quality of the control samples was assessed by overlaying bleached samples with RIN and control samples without RIN and assessing their similarity in terms of peak height and baseline level. Five control and four bleached samples were sent on dry-ice to the EMBL Genomics Core Facility [^5] where they were used to produce strand-specific libraries with ~110 base pairs (bp). These libraries were multiplexed and pair-end sequenced (50bp reads) in two lanes of a HiSeq 2500 (Illumina).

##Transcriptome assembly, annotation

Reads were quality controled using FastQC [^6] and quality filtered using the BioLite program filter_illumina.cpp [^7]. The surviving read pairs from all libraries were used to produce (using the command cat) two fastq files that were used for *de novo* transcriptome assembly in Trinity v2.0.6 (using the --normalize_reads flag). The resulting contigs (with lenght >=200bp) were annotated against the Uniprot (SwissProt) [^8] and *Amphimedon queenslandica* isoforms (Aqu2 proteins) [^9] using blastx v2.2.29+ with an expectation cutoff of 0.001. Only the best match per contig was saved and the blast results were saved using blast's XML format converted to a 25 column table [^10]. Both tables (i.e. [UNIPROT](https://github.com/sevragorgia/CBAS/tree/master/Annotations/Uniprot) and [Aqu2](https://github.com/sevragorgia/CBAS/tree/master/Annotations/AQU2)) are available for download in the [project repository](https://github.com/sevragorgia/CBAS). Gene Ontology [^11] annotations for the CBAS transcriptome were obtained by programmatically querying the [QuickGO Webservice](http://www.ebi.ac.uk/QuickGO/) with the transcriptome's UNIPROT annotations [^12] and a custom [perl script](https://github.com/sevragorgia/CBAS/blob/master/Scripts/Get_GO_Annotations.pl). For each CBAS transcript the "component", "function" and "process" GO terms associated with its UNIPROT best match were stored in the [project repository](https://github.com/sevragorgia/CBAS/tree/master/Annotations/GOs) as independent tab-separated files that can be easily modified to use as input files in TopGO [^13].

In addition, transcripts were translated using the program TransDecoder.LongOrfs [^14] and the resulting cds, mRNA, bed, gff3 and pep files stored in the [project repository](https://github.com/sevragorgia/CBAS/tree/master/Annotations/Transdecoder) and used to annotate the transcriptome against the [Pfam](http://pfam.xfam.org/) and [KEEG](http://www.genome.jp/kegg/) databases. For this, the perl script [pfam_scan.pl](ftp://ftp.ebi.ac.uk/pub/databases/Pfam/Tools/) and the webservice [BlastKOALA](http://www.kegg.jp/blastkoala/) were used; the resulting output files can be found in the [project repository.](https://github.com/sevragorgia/CBAS) Finally, the assembled transcripts were blasted (blastn) against a bacterial genomes database [^15].

All annotations were used to build an [annotation meta-table](https://github.com/sevragorgia/CBAS/blob/master/Annotations/Metatable/) using a [custom made perl script](https://github.com/sevragorgia/CBAS/blob/master/Scripts/Create_Transcriptome_Annotation_Table.pl) available in the project repository.

## Transcriptome completeness assessment

The CBAS transcriptome completeness was assessed by blasting against the CEGMA gene set of [Parra et al. 2007](http://bioinformatics.oxfordjournals.org/content/23/9/1061.abstract)[^16] using tblastn with an e-value of $1e^-19$ as implemented in the scrtipt [find_cegma_genes.py](https://bitbucket.org/wrf/galaxy-files/src). For details about the method see [^17].

##Differential gene expression analysis

Using the *de novo* assembled transcriptome, the individual libraries (i.e. control and bleached sponges) were mapped with RSEM and a transcript by sample count matrix was derived from the "gene" counts with the program [abundance_estimates_to_matrix.pl](https://github.com/sevragorgia/CBAS/tree/master/Counts/RSEM) provided as part of the Trinity package [^18]. The [count matrix](https://github.com/sevragorgia/CBAS/tree/master/Counts/) was used to find differentially expressed genes in control *vs.* bleached sponges (model = ~Treatment). For this, the package [DeSeq2](https://bioconductor.org/packages/release/bioc/html/DESeq2.html) was used. In brief, transcripts with 0 counts over all samples were removed from the matrix and Principal Component Analysis was used to assess the global expression pattern of control *vs.* bleached sponges and identify potential outliers. Size effects and dispersions were estimated with the DeSe2 methods **estimateSizeFactors** and **estimateDispersions** and differentially expressed transcripts were then infered using a Wald test (DeSeq2 method **nbinomWaldTest**). The resulting p-values were adjusted using the Benjamin-Hochberg correction. Transcripts with **log fold change $< -2$** or **log fold change $> 2$** and **adjusted p-value $< 0.01$** were considered as differentially expressed for further analyses.

A stand-alone R script to replicate the analysis is available in the [project repository](https://github.com/sevragorgia/CBAS/blob/master/Scripts) and can be run using the [count matrix](https://github.com/sevragorgia/CBAS/tree/master/Counts/CBAS_Bleaching_RSEM_Expression_Matrix.counts) and [sample information](https://github.com/sevragorgia/CBAS/tree/master/Counts/CBAS_Bleaching_RSEM_Expression_Matrix.info) provided. And in this version of the manuscript, the code used for several calculations is provided embedded as Rmarkdown snippets in the source code of this document.

##Gene Ontology Term enrichment analysis

In order to assess whether certain Gene Ontology terms are "enriched" among the set of differentially expressed genes a GO-term enrichment analysis was done using the R package [TopGO](https://bioconductor.org/packages/release/bioc/html/topGO.html). For this analysis, "background sets" of not differentially expressed transcripts with similar expression profile to the set of differentially expressed transcripts were created using the method **genefinder** of the package [genefilter](http://bioconductor.org/packages/release/bioc/html/genefilter.html) with the Manhattan distance. Background transcript sets were created for all differentially expressed transcripts (i.e. transcripts with log fold change $> |2|$ and $p<0.01$), for differentially upregulated genes (i.e. transcripts with log fold change $> 2$ and $p<0.01$) and for differentially downregulated genes (i.e. transcripts with log fold change $< -2$ and $p<0.01$). The background sets were then used to test for enrichment of certain GO-terms in the global set of differentially expressed transcripts (log fold change $> |2|$ and $p<0.01$), the set of upregulated genes (log fold change $> 2$ and $p<0.01$) and the set of downregulated genes (log fold change $< -2$ and $p<0.01$). For the enrichment analysis, a Fisher exact test with the *classic* algorithm implemented in the method **runTest** of [TopGo](https://bioconductor.org/packages/release/bioc/html/topGO.html) was used.


##Pfam domain enrichment analysis

In addition to the GO-Term enrichment analysis, and due to the difficulties in assigning a meaning to the GO annotations in our sponge model, a Pfam domain enrichment analysis was also done. Essentially the Pfam enrichment analysis works in a similar way that the GO-term enrichment analysis. First, a background set of genes not differentially expressed but showing similar expression patterns than the DEGs is calculated and used to provide a population of transcripts against which the differentially expressed transcripts can be compared. Once the background population of transcripts is available, the frequency with which a given domain is found in the background set of transcripts is compared with the frequency with which the same domain is found in the set of differentially expressed transcripts using an hypergeometric test. To account for multiple comparisons, the p-values are adjusted using the Benjamini-Hochberg correctino. The background distribution used for the Pfam enrichment domains was the same used for the analysis of GO-term enrichment.


#Results

```{r load_files, echo=FALSE, results='hide'}
#here we load some necessary files to make them available.

#meta-annotation table, read gziped file as if read.csv, i.e. no quotes, no comments.
meta_annotations<-read.table("../Annotations/Metatable/20161123_CBAS_Annotation_Metatable.csv.gz", head=T, sep="\t", quote="", comment.char="")

#histogram table
transcript_lengths<-read.csv("../Results/Reference_transcriptome_length_histogram.csv", head=T, sep="\t")

#load tpm and fpkm matrices
tpm_matrix<-read.csv("../Counts/CBAS_Bleaching_RSEM_Expression_TPM_Matrix.csv", sep="\t", header=TRUE)
fpkm_matrix<-read.csv("../Counts/CBAS_Bleaching_RSEM_Expression_FPKM_Matrix.csv", sep="\t", header=TRUE)

#load the transcript count matrix and sample information table. It is assumed that these files are store in the folder Count_Matrix in the folder used to cloned the CBAS repository. The folder structure of the repository must not be changed.
CBAS_DE<-read.csv("../Counts/CBAS_Bleaching_RSEM_Expression_Matrix.counts", head=T, sep="\t")
CBAS_DE_INFO<-read.csv("../Counts/CBAS_Bleaching_RSEM_Expression_Matrix.info", head=T)

```

##The transcriptome of the Common Blue Aquarium Sponge, a model cyanosponge

Per library, we obtained on average 26,385,834 ($\pm 3,360,778$) pairs of reads (50 bp long).  After cleaning, each library had an average of 24,942,084 ($\pm 3,420,083$) surviving pairs. The concatenated dataset thus had 199,536,668 pairs. Table 1 contains the information on the number of sequenced and surviving reads per library.

**Table 1.** Reads by library before and after quality filtering.

Library | Condition | Sequenced reads | Reads post cleaning | % Kept
:-----: | :-------: | :-------------: | :-----------------: | :-----:
1| Control | 33,836,615 | 32,397,726 | `r round((32397726/33836615)*100,2)`
2| Control | 26,740,977 | 25,252,825 | `r round((25252825/26740977)*100,2)`
3| Control | 22,823,936 | 21,016,976 | `r round((21016976/22823936)*100,2)`
4| Control | 24,166,051 | 22,655,601 | `r round((22655601/24166051)*100,2)`
5| Bleached | 26,579,563 | 25,067,523 | `r round((25067523/26579563)*100,2)`
6| Bleached | 25,448,522 | 24,229,217 | `r round((24229217/25448522)*100,2)`
7| Bleached | 22,823,936 | 21,016,976 | `r round((21016976/22823936)*100,2)`
8| Bleached | 24,166,051 | 22,655,601 | `r round((22655601/24166051)*100,2)`
Total Reads | | 211,086,672 | 199,536,668 | `r round((199536668/211086672)*100,2)`

***

*De novo* transcriptome assembly using the concatenated dataset resulted in 128,686 transcript $\gt 200$bp. The N50 of the transcriptome was 1,281 bp, and the median lenght of the assembled transcripts was `r median(meta_annotations$Length, na.rm=TRUE)` bp (MAD=`r mad(meta_annotations$Length, center=median(meta_annotations$Length), na.rm=TRUE, constant=1/quantile(meta_annotations$Length, probs=0.75, names=F))`). More details about the assembly can be found in Table 2 and the length distribution of the transcripts can be visualized in Figure 1.

**Table 2.** Statistics for the *de novo* assembled CBAS transcriptome

Statistic | Obtained value |
:-------: | :------------: |
GC content | 40.0 |
N50 | 1,281 |
Max. length | 19,309 |
Mean length |	803 |
Median length |453 |
Min. length |  224 |
Number of Transcripts | 128,686 |

***

```{r transcript_length_fig, echo=FALSE , fig.align='center'}
#cap transcript lenght at 10,000bp to improve the graph.    
selected_transcript_lengths<-subset(transcript_lengths, transcript_lengths$Length<10000)
ggplot(selected_transcript_lengths, aes(x=Length, y=Count)) + geom_bar(fill = "dark green", alpha=0.75, stat="identity") + theme_bw()

```

**Figure 1.** Transcript length distribution of CBAS reference transcriptome. Maximum length allowed equal 10,000 base-pairs.

***

Of the collection of transcripts, `r round(100*(sum(!is.na(meta_annotations$Protein))/(sum(is.na(meta_annotations$Protein))+sum(!is.na(meta_annotations$Protein)))),2)`% could be translated into proteins by Transdecoder. The majority of the translated transcripts were *Complete ORFs*, according to Transdecoder. The *Transdecoder ORF Types* distribution of the translated transcripts can be found in Table 3.

**Table 3.** *Transdecoder ORF Type* of the translated transcripts.

ORF Type | Count |  %  |
:------: | :---: | :-: |
3' partial | `r as.vector(table(meta_annotations$ORF_Type))[1]` |`r round(100*(as.vector(table(meta_annotations$ORF_Type))[1]/sum(as.vector(table(meta_annotations$ORF_Type)))), 2)` |
5' partial | `r as.vector(table(meta_annotations$ORF_Type))[2]` | `r round(100*(as.vector(table(meta_annotations$ORF_Type))[2]/sum(as.vector(table(meta_annotations$ORF_Type)))), 2)` |
Internal | `r as.vector(table(meta_annotations$ORF_Type))[4]` | `r round(100*(as.vector(table(meta_annotations$ORF_Type))[4]/sum(as.vector(table(meta_annotations$ORF_Type)))), 2)` |
Complete | `r as.vector(table(meta_annotations$ORF_Type))[3]` | `r round(100*(as.vector(table(meta_annotations$ORF_Type))[3]/sum(as.vector(table(meta_annotations$ORF_Type)))), 2)` |
Total | `r sum(as.vector(table(meta_annotations$ORF_Type)))` | `r round(100*sum(as.vector(table(meta_annotations$ORF_Type)))/sum(as.vector(table(meta_annotations$ORF_Type))), 2)` |

***

Regarding the annotation of the translated transcripts [^19], `r round(100*(sum(!is.na(meta_annotations$Uniprot_match))/(sum(is.na(meta_annotations$Uniprot_match))+sum(!is.na(meta_annotations$Uniprot_match)))), 2)`% had a matching *Uniprot* annotation. The number of transcripts matching an *Amphimedon queenslandica* (Aqu2) protein was slightly higher, `r round(100*(sum(!is.na(meta_annotations$Aqu2_match))/(sum(is.na(meta_annotations$Aqu2_match))+sum(!is.na(meta_annotations$Aqu2_match)))), 2)`%. *Gene Ontology Component*, *Function* and *Process* annotations could be retrieved for `r round(100*(sum(!is.na(meta_annotations$GO_Component))/(sum(is.na(meta_annotations$GO_Component))+sum(!is.na(meta_annotations$GO_Component)))), 2)`%, `r round(100*(sum(!is.na(meta_annotations$GO_Function))/(sum(is.na(meta_annotations$GO_Function))+sum(!is.na(meta_annotations$GO_Function)))), 2)`% and `r round(100*(sum(!is.na(meta_annotations$GO_Process))/(sum(is.na(meta_annotations$GO_Process))+sum(!is.na(meta_annotations$GO_Process)))), 2)`% of the transcripts, respectively. Additionally, `r round(100*(sum(!is.na(meta_annotations$Pfam_Domains))/(sum(is.na(meta_annotations$Pfam_Domains))+sum(!is.na(meta_annotations$Pfam_Domains)))), 2)`% of the transcripts could be annotated with *Pfam* domain information. In contrast, only `r round(100*(sum(!is.na(meta_annotations$KEGG))/(sum(is.na(meta_annotations$KEGG))+sum(!is.na(meta_annotations$KEGG)))), 2)`% of the assembled transcripts could be annotated against the *KEGG* database.


```{r annotation_success_fig, echo=FALSE, fig.align='center'}
#select only transcripts translating to protein
meta_annotations_NoNAs<-subset(meta_annotations, meta_annotations$Protein!="NA")

#prepare a data frame for the next visualization; basically, prepare a table of annotation presence/absence by ORF_type, melt the table and add the database information.
uniprotMelted<-melt(table(meta_annotations_NoNAs$ORF_Type,!is.na(meta_annotations_NoNAs$Uniprot_match)))
uniprotMelted[, "Annotation"]<-rep("Uniprot", 8)

aqu2Melted<-melt(table(meta_annotations_NoNAs$ORF_Type,!is.na(meta_annotations_NoNAs$Aqu2_match)))
aqu2Melted[, "Annotation"]<-rep("Aqu2", 8)

GOComponentMelted<-melt(table(meta_annotations_NoNAs$ORF_Type,!is.na(meta_annotations_NoNAs$GO_Component)))
GOComponentMelted[, "Annotation"]<-rep("GO-term: Component", 8)

GOFunctionMelted<-melt(table(meta_annotations_NoNAs$ORF_Type,!is.na(meta_annotations_NoNAs$GO_Function)))
GOFunctionMelted[, "Annotation"]<-rep("GO-term: Function", 8)

GOProcessMelted<-melt(table(meta_annotations_NoNAs$ORF_Type,!is.na(meta_annotations_NoNAs$GO_Process)))
GOProcessMelted[, "Annotation"]<-rep("GO-term: Process", 8)

pfamMelted<-melt(table(meta_annotations_NoNAs$ORF_Type,!is.na(meta_annotations_NoNAs$Pfam_Domains)))
pfamMelted[, "Annotation"]<-rep("Pfam", 8)

KEGGMelted<-melt(table(meta_annotations_NoNAs$ORF_Type,!is.na(meta_annotations_NoNAs$KEGG)))
KEGGMelted[, "Annotation"]<-rep("KEGG", 8)

#now concat all previous dataframes:
annotations_per_ORF_Type<-rbind(uniprotMelted,aqu2Melted,GOComponentMelted,GOFunctionMelted, GOProcessMelted, pfamMelted, KEGGMelted)
colnames(annotations_per_ORF_Type)<-c("ORF_Type", "Annotation_present", "Count", "Database")

ggplot(annotations_per_ORF_Type, aes(Database,Count)) + geom_bar(stat="identity",  aes(fill=Annotation_present)) + theme_bw() + theme(axis.text.x=element_text(angle=45, vjust=0.9, hjust=1)) + scale_fill_discrete(name="Annotation found")

```
**Figure 2.** Annotation success by database for transcripts translated by Transdecoder.

***

Regarding annotation success, different *Transdecoder ORF Types* had different annotation success rates (Fig. 3) with *complete ORFs* having higher annotation sucess than other *ORF types* and *3' Partial ORFs* having the lowest annotation success.

```{r annotation_count_byDB_Fig, echo=FALSE, fig.align='center'}
#using the previously generated data frame, provide a more detail account of the annotation success by ORF Type

ggplot(subset(annotations_per_ORF_Type, Annotation_present==TRUE), aes(Database,Count)) + geom_bar(stat="identity",  aes(fill=ORF_Type)) + theme_bw() + theme(axis.text.x=element_text(angle=45, vjust=0.9, hjust=1)) + scale_fill_discrete(name="Transdecoder ORF Type", labels=c("3' Partial", "5' Partial", "Complete", "Internal"))

```
**Figure 3.** Annotation count by database for different types of ORF as defined by Transdecoder.

***

For annotation against Uniprot and Aqu2 we used a permissive evalue (0.001) to query these databases. Thus, we risk obtaining annotations that are only partial matches or that are of doubtful homology. Despite our permissive annotation strategy, the mean evalues obtained for the annotations against Uniprot and Aqu2 had clearly lower values than the threshold set (i.e. $`r mean(meta_annotations_NoNAs$evalue, na.rm=TRUE)` \pm `r sd(meta_annotations_NoNAs$evalue, na.rm=TRUE)`$ and $`r mean(meta_annotations_NoNAs$evalue.1, na.rm=TRUE)` \pm `r sd(meta_annotations_NoNAs$evalue.1, na.rm=TRUE)`$, respectively). Interestintly, the mean evalues obtained for both Uniprot and Aqu2 annotations were similar for all *Transdecoder ORF types* (Table 4) and the maximum evalue obtained after querying these two databases was $1x10^{-05}$ [^20].

**Table 4.** Mean evalue by Transdecoder ORF type for annotations obtained from the Uniprot or Aqu2 databases.

Transdecoder ORF Type | Database | Mean evalue (SD) |
:-----: | :------: | :--------------: |
3' partial | Uniprot | $`r as.vector(tapply(meta_annotations$evalue, meta_annotations$ORF_Type, mean, na.rm=TRUE))[1]`$ ($`r as.vector(tapply(meta_annotations$evalue, meta_annotations$ORF_Type, sd, na.rm=TRUE))[1]`$) 
5' partial | Uniprot | $`r as.vector(tapply(meta_annotations$evalue, meta_annotations$ORF_Type, mean, na.rm=TRUE))[2]`$ ($`r as.vector(tapply(meta_annotations$evalue, meta_annotations$ORF_Type, sd, na.rm=TRUE))[2]`$)
Internal | Uniprot | $`r as.vector(tapply(meta_annotations$evalue, meta_annotations$ORF_Type, mean, na.rm=TRUE))[4]`$ ($`r as.vector(tapply(meta_annotations$evalue, meta_annotations$ORF_Type, sd, na.rm=TRUE))[4]`$)
Complete | Uniprot | $`r as.vector(tapply(meta_annotations$evalue, meta_annotations$ORF_Type, mean, na.rm=TRUE))[3]`$ ($`r as.vector(tapply(meta_annotations$evalue, meta_annotations$ORF_Type, sd, na.rm=TRUE))[3]`$)
 | | 
3' partial | Aqu2 | $`r as.vector(tapply(meta_annotations$evalue.1, meta_annotations$ORF_Type, mean, na.rm=TRUE))[1]`$ ($`r as.vector(tapply(meta_annotations$evalue.1, meta_annotations$ORF_Type, sd, na.rm=TRUE))[1]`$) 
5' partial | Aqu2 | $`r as.vector(tapply(meta_annotations$evalue.1, meta_annotations$ORF_Type, mean, na.rm=TRUE))[2]`$ ($`r as.vector(tapply(meta_annotations$evalue.1, meta_annotations$ORF_Type, sd, na.rm=TRUE))[2]`$)
Internal | Aqu2 | $`r as.vector(tapply(meta_annotations$evalue.1, meta_annotations$ORF_Type, mean, na.rm=TRUE))[4]`$ ($`r as.vector(tapply(meta_annotations$evalue.1, meta_annotations$ORF_Type, sd, na.rm=TRUE))[4]`$)
Complete  | Aqu2 | $`r as.vector(tapply(meta_annotations$evalue.1, meta_annotations$ORF_Type, mean, na.rm=TRUE))[3]`$ ($`r as.vector(tapply(meta_annotations$evalue.1, meta_annotations$ORF_Type, sd, na.rm=TRUE))[3]`$)

***

Finally, in terms of completeness, we recovered 243 out of 248 KOGs (i.e. $`r round(100*(243/248),2)`$%) from the CBAS transcriptome. Yet, the number of transcripts classified as *High-confidence, full length matches* was only 175 (i.e. $`r round(100*(175/248),2)`$%). In addition, six transcripts were categorized as *Probable full length matches*, six more were tagged as matching a KOG that was slightly shorter than the query and 4 transcripts matched a KOG that was much longer than the query. Thus, in total $`r 175+6+6+4`$ (i.e. $`r round(100*((175+6+6+4)/248),2)`$%) transcripts can be considered high confidence KOG matches. Transcripts matching KOGs that were much shorter and transcripts probably representing missassemblies amount to 22 and 30, respectively (i.e. $`r round(100*((22+30)/248),2)`$%).

##Global gene expression patterns change due to symbiont inactivation

```{r prepare_DE_analysis_matrix, include=FALSE, results='hide'}

#Remove genes that have no counts over all samples
CBAS_DE<-CBAS_DE[(rowSums(CBAS_DE) > 0),]

#create DeSeq2 object
CBAS_DeSeq<-DESeqDataSetFromMatrix(countData=CBAS_DE, colData=CBAS_DE_INFO, design=~condition)

#relevel the factors so that Control" is the reference treatment
CBAS_DeSeq$condition<-relevel(CBAS_DeSeq$condition,ref="Control")

#estimate size factors
#If all size factors are roughly equal to one, the libraries have been sequenced equally deeply.
CBAS_DeSeq<-estimateSizeFactors(CBAS_DeSeq)

#get rows with all non-zero counts
non_zero_rows<-apply(counts(CBAS_DeSeq), 1, function(x){all(x>0)})

#get all rows
all_rows<-apply(counts(CBAS_DeSeq), 1, function(x){all(x>=0)})

```

The count matrix used to investigate changes in gene expression in Bleached *vs.* Control sponges had $`r sum(all_rows)`$ rows with counts. Of these, however, only $`r sum(non_zero_rows)`$ had counts in all samples (i.e. the transcript was detected in all sequenced libraries). The inspection of the cummulative density distribution and of the density distribution of normalized counts (Fig. 5) for either all rows (not shown) or only the non-zero rows in the matrix showed similar patterns for all libraries indicating that they were sequenced at similar depths and can be compared safely. 

```{r normalized_counts_cumulativeDist_qc_figure, echo=FALSE, fig.align='center', fig.height=10, fig.width=10}
par(mfrow = c(2,1), oma=c(4,4,2,0.5))
#cummulative distribution of normalized counts for non-zero rows
multiecdf(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ], xlab="Mean counts", ylab="Cummulative density", xlim=c(0,1000), main="")

#density of normalized counts
multidensity(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ], xlab="Mean counts", main="", xlim=c(0,1000))
```
**Figure 5.** Cummulative density distribution of normalized counts and density distribution of normalized counts of RNA-Seq libraries prepared samples for *bleached* and *control* **CBAS** samples.

***

A pairwise comparison of the individual libraries (Fig 6.) provided further evidence for the technical similarity of the libraries.

```{r MDPlots_library_01_qc_figure, echo=FALSE, fig.align='center', fig.height=10, fig.width=10}
par(mfrow = c(2,4), oma=c(4,4,2,0.5))
#sample comparisons
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(1,2), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[2]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(1,3), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[3]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(1,4), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[4]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(1,5), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[5]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(1,6), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[6]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(1,7), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[7]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(1,8), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[8]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(1,9), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[9]))
title(paste( "Library", colnames(CBAS_DeSeq)[1], "vs."), outer=TRUE)
mtext("Mean log-transformed counts", side=1, outer=TRUE)
mtext("Mean log fold", side=2, outer=TRUE)
```


```{r MDPlots_library_02_qc_figure, echo=FALSE, fig.align='center', fig.height=10, fig.width=10}
par(mfrow = c(2,4), oma=c(4,4,2,0.5))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(2,3), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[3]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(2,4), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[4]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(2,5), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[5]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(2,6), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[6]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(2,7), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[7]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(2,8), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[8]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(2,9), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[9]))
title(paste( "Library", colnames(CBAS_DeSeq)[2], "vs."), outer=TRUE)
mtext("Mean log-transformed counts", side=1, outer=TRUE)
mtext("Mean log fold", side=2, outer=TRUE)
```


```{r MDPlots_library_03_qc_figure, echo=FALSE, fig.align='center', fig.height=10, fig.width=10}
par(mfrow = c(2,4), oma=c(4,4,2,0.5))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(3,4), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[4]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(3,5), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[5]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(3,6), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[6]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(3,7), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[7]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(3,8), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[8]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(3,9), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[9]))
title(paste( "Library", colnames(CBAS_DeSeq)[3], "vs."), outer=TRUE)
mtext("Mean log-transformed counts", side=1, outer=TRUE)
mtext("Mean log fold", side=2, outer=TRUE)
```


```{r MDPlots_library_04_qc_figure, echo=FALSE, fig.align='center', fig.height=10, fig.width=10}
par(mfrow = c(2,4), oma=c(4,4,2,0.5))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(4,5), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[5]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(4,6), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[6]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(4,7), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[7]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(4,8), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[8]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(4,9), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[9]))
title(paste( "Library", colnames(CBAS_DeSeq)[4], "vs."), outer=TRUE)
mtext("Mean log-transformed counts", side=1, outer=TRUE)
mtext("Mean log fold", side=2, outer=TRUE)
```


```{r MDPlots_library_05_qc_figure, echo=FALSE, fig.align='center', fig.height=5, fig.width=10}
par(mfrow = c(1,4), oma=c(4,4,2,0.5))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(5,6), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[6]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(5,7), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[7]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(5,8), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[8]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(5,9), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[9]))
title(paste( "Library", colnames(CBAS_DeSeq)[5], "vs."), outer=TRUE)
mtext("Mean log-transformed counts", side=1, outer=TRUE)
mtext("Mean log fold", side=2, outer=TRUE)
```


```{r MDPlots_library_06_qc_figure, echo=FALSE, fig.align='center', fig.height=5, fig.width=10}
par(mfrow = c(1,4), oma=c(4,4,2,0.5))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(6,7), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[7]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(6,8), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[8]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(6,9), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[9]))
title(paste( "Library", colnames(CBAS_DeSeq)[6], "vs."), outer=TRUE)
mtext("Mean log-transformed counts", side=1, outer=TRUE)
mtext("Mean log fold", side=2, outer=TRUE)
```


```{r MDPlots_library_07_qc_figure, echo=FALSE, fig.align='center', fig.height=5, fig.width=10}
par(mfrow = c(1,4), oma=c(4,4,2,0.5))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(7,8), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[8]))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(7,9), xlab="", ylab="", main=paste(colnames(CBAS_DeSeq)[9]))
title(paste( "Library", colnames(CBAS_DeSeq)[7], "vs."), outer=TRUE)
mtext("Mean log-transformed counts", side=1, outer=TRUE)
mtext("Mean log fold", side=2, outer=TRUE)
```


```{r MDPlots_library_08_qc_figure, echo=FALSE, fig.align='center', , fig.height=5, fig.width=10}
par(mfrow = c(1,4), oma=c(4,4,2,0.5))
MDPlot(counts(CBAS_DeSeq, normalized=T)[non_zero_rows, ],c(8,9), xlab="", ylab="")
title(paste( "Library", colnames(CBAS_DeSeq)[8], "vs.", colnames(CBAS_DeSeq)[9]), outer=TRUE)
mtext("Mean log-transformed counts", side=1, outer=TRUE)
mtext("Mean log fold", side=2, outer=TRUE)
```
**Figure 6.** Pairwise library comparisons based on the relation between the *Mean log-fold* and the *Mean (log-transformed) counts*. In general, no trend should be observed in the pairwise comparisons.

***

Libraries were also compared in terms of the *FPKM* and *TPM* distribution of the transcripts (Fig. 7). This analysis revealed that two libraries (i.e. CBAS_Control_2 and CBAS_Control_3) differed markedly from all other sequenced libraries. Thus, we restricted the count matrix to include only *trinity genes* that could be translated using Transdecoder (29,705 transcripts) . After this, the libraries were comparable in terms of the distribution of TPM and FPKM values. The analysis of differential expression was conducted on this reduced data matrix.


```{r prepare_TPM_and_FPKM_matrices_for_plotting, include=FALSE, results='hide'}
#melt for graphs
tpm_matrix_melted<-melt(tpm_matrix)
colnames(tpm_matrix_melted)<-c("Transcript_ID", "Library", "Value")
tpm_matrix_melted[,"Gen_set"]<-rep("All Transcripts", nrow(tpm_matrix_melted))
tpm_matrix_melted[,"Variable"]<-rep("TPM", nrow(tpm_matrix_melted))

fpkm_matrix_melted<-melt(fpkm_matrix)
colnames(fpkm_matrix_melted)<-c("Transcript_ID", "Library", "Value")
fpkm_matrix_melted[,"Gen_set"]<-rep("All Transcripts", nrow(fpkm_matrix_melted))
fpkm_matrix_melted[,"Variable"]<-rep("FPKM", nrow(fpkm_matrix_melted))

#create a new tpm matrix with only those genes sucessfully transdecoded
tpm_matrix_transdecoded_only<-tpm_matrix
tpm_matrix_transdecoded_only[, "WasTransdecoded"]<-tpm_matrix$Transcript_ID %in% meta_annotations_NoNAs$Trinity_gene
tpm_matrix_transdecoded_only<-subset(tpm_matrix_transdecoded_only, tpm_matrix_transdecoded_only$WasTransdecoded ==T)
tpm_matrix_transdecoded_only<-subset(tpm_matrix_transdecoded_only, ,-c(WasTransdecoded))

#melt for graphs
tpm_matrix_transdecoded_only_melted<-melt(tpm_matrix_transdecoded_only)
colnames(tpm_matrix_transdecoded_only_melted)<-c("Transcript_ID", "Library", "Value")
tpm_matrix_transdecoded_only_melted[,"Gen_set"]<-rep("Transdecoded Transcripts", nrow(tpm_matrix_transdecoded_only_melted))
tpm_matrix_transdecoded_only_melted[,"Variable"]<-rep("TPM", nrow(tpm_matrix_transdecoded_only_melted))

#create a new fpkm matrix with only those genes sucessfully transdecoded
fpkm_matrix_transdecoded_only<-fpkm_matrix
fpkm_matrix_transdecoded_only[, "WasTransdecoded"]<-fpkm_matrix$Transcript_ID %in% meta_annotations_NoNAs$Trinity_gene
fpkm_matrix_transdecoded_only<-subset(fpkm_matrix_transdecoded_only, fpkm_matrix_transdecoded_only$WasTransdecoded ==T)
fpkm_matrix_transdecoded_only<-subset(fpkm_matrix_transdecoded_only, ,-c(WasTransdecoded))

fpkm_matrix_transdecoded_only_melted<-melt(fpkm_matrix_transdecoded_only)
colnames(fpkm_matrix_transdecoded_only_melted)<-c("Transcript_ID", "Library", "Value")
fpkm_matrix_transdecoded_only_melted[,"Gen_set"]<-rep("Transdecoded Transcripts", nrow(fpkm_matrix_transdecoded_only_melted))
fpkm_matrix_transdecoded_only_melted[,"Variable"]<-rep("FPKM", nrow(fpkm_matrix_transdecoded_only_melted))

tpm_fpkm_matrix_melted<-rbind(tpm_matrix_melted, fpkm_matrix_melted, tpm_matrix_transdecoded_only_melted, fpkm_matrix_transdecoded_only_melted)

```

```{r TPM_figure, echo=FALSE, fig.align='center', fig.height=10, fig.width=10}

ggplot(tpm_fpkm_matrix_melted, aes(Library,Value+0.0001)) + geom_boxplot() + theme_bw() + scale_y_log10(name="") + theme(axis.text.x=element_text(angle=45, vjust=0.9, hjust=1)) + scale_x_discrete(name="Library", labels=c("CBAS_Bleached_1", "CBAS_Bleached_2", "CBAS_Bleached_3", "CBAS_Bleached_4", "CBAS_Bleached_5", "CBAS_Control_1", "CBAS_Control_2", "CBAS_Control_3", "CBAS_Control_4")) + facet_grid(Gen_set~Variable)

```
**Figure 7.** TPM and FPKM distribution in datasets including all trinity genes (All transcripts) and only trinity genes that could be translated with trandescoder (Transdecoded transcripts). In general, libraries should have similar TPM/FPKM distributions to be comparable.

***

```{r prepare_reduced_DE_dataset, include=FALSE, results='hide'}
#select only transcripts that could be transdecoded
#first copy the original matrix
CBAS_DE_Transdecoded_Only<-CBAS_DE
#then check if the transcript was transdecoded
CBAS_DE_Transdecoded_Only[, "WasTransdecoded"]<-rownames(CBAS_DE) %in% meta_annotations_NoNAs$Trinity_gene
#then subset based on that
CBAS_DE_Transdecoded_Only<-subset(CBAS_DE_Transdecoded_Only, CBAS_DE_Transdecoded_Only$WasTransdecoded == T)
#finally, delete the column with the true/false value for transdecoder success
CBAS_DE_Transdecoded_Only<-subset(CBAS_DE_Transdecoded_Only, ,-c(WasTransdecoded))

CBAS_DeSeq_Transdecoded_Only<-DESeqDataSetFromMatrix(countData=CBAS_DE_Transdecoded_Only, colData=CBAS_DE_INFO, design=~condition)

#relevel the factors so that "Control" is the reference treatment
CBAS_DeSeq_Transdecoded_Only$condition<-relevel(CBAS_DeSeq_Transdecoded_Only$condition,ref="Control")

#estimate size factors
#If all size factors are roughly equal to one, the libraries have been sequenced equally deeply.
CBAS_DeSeq_Transdecoded_Only<-estimateSizeFactors(CBAS_DeSeq_Transdecoded_Only)

#transform the data to rlog
CBAS_DeSeq_Transdecoded_Only_rlog<-rlogTransformation(CBAS_DeSeq_Transdecoded_Only, blind = T)
```

For the analysis of differentially expressed genes, the count matrix was transformed using the *rlog* transformation available in the R package DeSeq2. A cluster analysis based on the between-sample distances calculated using the *rlog* transformed counts grouped samples in two groups matching the *control* and *treatment* groups. Interestingly one treatment sample behaved in an anomalous manner, clustering with neither the treatment nor the control group. This sample (i.e. CBAS_Bleached_5) was also found to be different in a Principal Component Analysis (PCA) conducted on the *rlog* transformed count matrix.

***

```{r sample_heat_pca_plot, echo=FALSE, fig.align='center', fig.height=10, fig.width=10}
#produce a heat plot using the transformed distances
CBAS_DeSeq_Transdecoded_Only_distances<-dist(t(assay(CBAS_DeSeq_Transdecoded_Only_rlog)))

par(mfrow = c(2,1), oma=c(4,4,2,0.5))
heatmap.2(as.matrix(CBAS_DeSeq_Transdecoded_Only_distances), trace="none", cexCol=1.15, labRow=FALSE, dendrogram=c("column"), col=rev(colorRampPalette(brewer.pal(9, "GnBu"))(100)))

#PCA of samples
plotPCA(CBAS_DeSeq_Transdecoded_Only_rlog, intgroup=c("condition"))

```

**Figure 9.** Cluster and Principal Component Analysis of the *rlog* transformed counts for *bleached vs. control* CBAS specimens.

***

If sample *CBAS_Bleached_5* is removed from the analysis, *bleached* samples are grouped together while *control* sponges are divided in two groups in both the cluster analysis and the principal component analysis.


```{r drop_anomalous_sample_and_replot, echo=FALSE, fig.align='center', fig.height=10, fig.width=10}
#remove outlier samples: CBAS_Bleached_5
outliers=c("CBAS_Bleached_5")
CBAS_DeSeq_Transdecoded_Only_NoOutliers<-CBAS_DeSeq_Transdecoded_Only[,!(colnames(CBAS_DeSeq_Transdecoded_Only) %in% outliers)]

#repeat above analyses
CBAS_DeSeq_Transdecoded_Only_NoOutliers_rlog<-rlogTransformation(CBAS_DeSeq_Transdecoded_Only_NoOutliers, blind = T)

#produce a heat plot using the transformed distances
CBAS_DeSeq_Transdecoded_Only_NoOutliers_distances<-dist(t(assay(CBAS_DeSeq_Transdecoded_Only_NoOutliers_rlog)))

#now replot
par(mfrow = c(2,1), oma=c(4,4,2,0.5))
heatmap.2(as.matrix(CBAS_DeSeq_Transdecoded_Only_NoOutliers_distances), cexCol=1.15, trace="none", labRow=FALSE, dendrogram=c("column"), col=rev(colorRampPalette(brewer.pal(9, "GnBu"))(100)))

#PCA of samples
plotPCA(CBAS_DeSeq_Transdecoded_Only_NoOutliers_rlog, intgroup=c("condition"))
```

**Figure 10.** Cluster and Principal Component Analysis of the *rlog* transformed counts for *bleached vs. control* CBAS specimens after removing sample *CBAS_Bleached_5*.

***

```{r differential_expression_analysis, include=FALSE, results='hide'}
#here we assess for global differences in expression using the function adonis from the package vegan.

light_treatments<-data.frame(Condition=c("T","T","T","T","C","C","C","C"))

#now use the function adonis to test for differences between treatments. By default adonis uses the bray-curtis distance.
adonis(t(assay(CBAS_DeSeq_Transdecoded_Only_NoOutliers_rlog))~Condition, data=light_treatments, method="euclidean")

######

CBAS_DeSeq_Transdecoded_Only_NoOutliers<-estimateSizeFactors(CBAS_DeSeq_Transdecoded_Only_NoOutliers)
CBAS_DeSeq_Transdecoded_Only_NoOutliers<-estimateDispersions(CBAS_DeSeq_Transdecoded_Only_NoOutliers)

#need to plot this.
#plotDispEsts(CBAS_DeSeq_Transdecoded_Only_NoOutliers)

#wald test
CBAS_DeSeq_Transdecoded_Only_NoOutliers<-nbinomWaldTest(CBAS_DeSeq_Transdecoded_Only_NoOutliers)
CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results<-results(CBAS_DeSeq_Transdecoded_Only_NoOutliers, pAdjustMethod = "BH")

#need to use this in the results
#number of DE genes at 0.01 significance level
CBAS_DE_Genes<-table(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results$padj < 0.01)

#number of overexpressed genes at 0.01 significance level and log fold change > 2
CBAS_DE_Genes_Over<-table(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results$padj < 0.01 & CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results$log2FoldChange >= 2)

#number of underexpressed genes at 0.01 significance level and log fold change < -2
CBAS_DE_Genes_Under<-table(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results$padj < 0.01 & CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results$log2FoldChange <= -2)

#get significant genes; uncomment the write.csv method lines if you want to save a new file, otherwise leave commented to use the files in the repo.
degs_names<-rownames(subset(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results, padj<0.01 & abs(log2FoldChange) >= 2))
#write.csv(degs_names, "../Results/DEGs/all_degs_p001_2LFC.csv")

#get significantly overexpressed in treatment:
over_deg_names<-rownames(subset(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results, padj<0.01 & log2FoldChange >= 2))
#write.csv(over_deg_names, "../Results/DEGs/over_degs_p001_2LFC.csv")

#get significantly underexpressed in treatment:
under_deg_names<-rownames(subset(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results, padj<0.01 & log2FoldChange <= -2))
#write.csv(under_deg_names, "../Results/DEGs/under_degs_p001_2LFC.csv")

```

We detected significant differences in the global expression patters bewteen treated and control sponges (Adonis PseudoF = 5.1164, df = 1, p-value = 0.039). In this reduced dataset, a total of `r as.vector(CBAS_DE_Genes)[2]` transcripts were differentially expressed between the *control* and *bleached* sponges (Fig. 11). Of these transcripts, `r as.vector(CBAS_DE_Genes_Over)[2]` were overexpressed (with a log2 fold change higher or equal to 2) in *bleached vs. control* sponges and `r as.vector(CBAS_DE_Genes_Under)[2]` were expressed at lower levels (a log2 fold change lower or equal than -2) in *bleached vs. control* specimens.

```{r MA_plot, echo=FALSE, fig.align='center', fig.height=10, fig.width=10}
par(mfrow=c(2,1), oma=c(2,2,2,2))


#select only the DEGs from the count matrix and store in a new object for cluster plotting; to be later used to calculate a network.
CBAS_DeSeq_Transdecoded_Only_NoOutliers_DEGs <- CBAS_DeSeq_Transdecoded_Only_NoOutliers[rownames(CBAS_DeSeq_Transdecoded_Only_NoOutliers) %in% degs_names, ]

CBAS_DeSeq_Transdecoded_Only_NoOutliers_overDEGs <- CBAS_DeSeq_Transdecoded_Only_NoOutliers[rownames(CBAS_DeSeq_Transdecoded_Only_NoOutliers) %in% over_deg_names, ]

CBAS_DeSeq_Transdecoded_Only_NoOutliers_underDEGs <- CBAS_DeSeq_Transdecoded_Only_NoOutliers[rownames(CBAS_DeSeq_Transdecoded_Only_NoOutliers) %in% under_deg_names, ]

heatmap.2(log2(counts(CBAS_DeSeq_Transdecoded_Only_NoOutliers_DEGs, normalized=T)+1), cexCol=0.75, labRow=FALSE, scale="row", trace = "none", dendrogram = "column", col= colorRampPalette(rev(brewer.pal(9, "RdBu"))))

plotMA(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results, alpha=0.01)


```

**Figure 11.** MA-plot showing the relation between log-fold change and mean count for each analyzed CBAS transcript. Transcripts significant at 0.01 are highlighted in red.

***

It is worth noting that DeSeq2 was able to adecuately model the variance in the dataset and could correctly calculate the p-values for the analyzed transcripts (Fig 12).


```{r probability_plot, echo=FALSE, fig.align='center'}
#plot of p values
hist(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results$pvalue, main = "", xlab="p-values")
```

**Figure 12.** Histogram of the p-values obtained for the transcripts analyzed using DeSeq2. A uniform distribution between 0 and 1, with a peak at zero, should be observed if the variance of the dataset could be correctly modelled.

***

```{r expression_heat_maps, echo=FALSE, fig.align='center', fig.height=15, fig.width=10}
#par(oma=c(4,2,2,4))
#first generate a list of genes with a high LFC between treatments
#highLFC_deg_names<-rownames(subset(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results, padj<0.01 & abs(log2FoldChange) >= 6.0))

#then use those genes to present a heatmap
#heatmap.2(log2(counts(CBAS_DeSeq_Transdecoded_Only_NoOutliers, normalized=T)[rownames(CBAS_DeSeq_Transdecoded_Only_NoOutliers) %in% highLFC_deg_names, ]+1), cexCol=1, cexRow=0.8, scale="row", trace = "none", dendrogram = "column", col= colorRampPalette(rev(brewer.pal(9, "RdBu"))))

#**Figure 13.** Heatplot showing transcripts with a high log-fold change (LFC $\geq$ 6) between treatments.

#***
```

##The expression of immune response related transcripts changes between symbiontic states

```{r prepare_for_GO_analysis, include=FALSE, results='hide'}
#ontologies: MF=Molecular Function, BP=Biochemical Process, CC=Cellular Component

#get base mean to get the background genes for GO analysis
BaseMean<-as.matrix(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results[, "baseMean", drop=F])

#find 10 genes with similar expression profile to serve as background in go enrichment analysis
GO_Background<-genefinder(BaseMean, degs_names, 8, method="manhattan")
GO_Over_Background<-genefinder(BaseMean, over_deg_names, 8, method="manhattan")
GO_Under_Background<-genefinder(BaseMean, under_deg_names, 8, method="manhattan")

#get the names of the selected genes
GO_Background_Gene_Names<-rownames(BaseMean)[as.vector(sapply(GO_Background, function(x)x$indices))]
GO_Over_Background_Gene_Names<-rownames(BaseMean)[as.vector(sapply(GO_Over_Background, function(x)x$indices))]
GO_Under_Background_Gene_Names<-rownames(BaseMean)[as.vector(sapply(GO_Under_Background, function(x)x$indices))]

#remove degs from background if necessary
GO_Background_Gene_Names<-setdiff(GO_Background_Gene_Names, degs_names)
GO_Over_Background_Gene_Names<-setdiff(GO_Over_Background_Gene_Names, over_deg_names)
GO_Under_Background_Gene_Names<-setdiff(GO_Under_Background_Gene_Names, under_deg_names)

#uncomment the following line to save the names. Leave as comments to use the files already on the repo later on.
#write.csv(GO_Background_Gene_Names, "../Results/DEGs/Back_degs_p001_2LFC.csv")
#write.csv(GO_Over_Background_Gene_Names, "../Results/DEGs/Back_over_degs_p001_2LFC.csv")
#write.csv(GO_Under_Background_Gene_Names, "../Results/DEGs/Back_under_degs_p001_2LFC.csv")
```

For Gene Ontology (GO) enrichment analyses we were able to select a background set of transcripts showing similar expression patterns but no significant change between conditions for all transcripts as well as for overexpressed and underexpressed transcripts (Fig. 13). Enriched Function, Process and Compartment GO terms for over- and underexpressed genes can be found in Tables 5-10.

```{r plot_back_vs_forground_dist, echo=FALSE, fig.align='center', fig.height=10, fig.width=10}
#number of background genes
#length(GO_Background_Gene_names)
#length(GO_Over_Background_Gene_names)
#length(GO_Under_Background_Gene_names)

#plot the back and forground
par(mfrow=c(1,3))
multidensity( list(fore=log2(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results[degs_names, "baseMean"]),  back=log2(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results[GO_Background_Gene_Names, "baseMean"])),  xlab="log2 mean counts", main = "")

multidensity( list(fore=log2(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results[over_deg_names, "baseMean"]),  back=log2(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results[GO_Over_Background_Gene_Names, "baseMean"])),  xlab="log2 mean counts", main = "")

multidensity( list(fore=log2(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results[under_deg_names, "baseMean"]),  back=log2(CBAS_DeSeq_Transdecoded_Only_NoOutliers_Results[GO_Under_Background_Gene_Names, "baseMean"])),  xlab="log2 mean counts", main = "")

```

```{r Over_GO_analysis, include=FALSE, results='hide'}
#overexpressed genes only
#function GO analysis
overdegs_Function_GO<-readMappings("../Results/GOs/over_degs_p001_2LFC.functions.gos")
overback_Function_GO<-readMappings("../Results/GOs/Back_over_degs_p001_2LFC.functions.gos")

over_universe_for_function_topgo<-c(overdegs_Function_GO, overback_Function_GO)

#get names of genes in different groups
over_genes_of_interest_for_function<-names(overdegs_Function_GO)
over_genes_in_background_for_function<-names(overback_Function_GO)
over_genes_in_universe_for_function<-names(over_universe_for_function_topgo)

#get the list of genes of interest in the universe
over_genes_of_interest_list_for_function<-factor(as.integer(over_genes_in_universe_for_function %in% over_genes_of_interest_for_function))
names(over_genes_of_interest_list_for_function)<-over_genes_in_universe_for_function

#create a topGO object for Molecular Function
over_functions_go_data<-new("topGOdata", ontology="MF", allGenes=over_genes_of_interest_list_for_function, annot=annFUN.gene2GO, gene2GO=over_universe_for_function_topgo)

#create a test object
over_resultsFisher_functions<-runTest(over_functions_go_data, algorithm = "classic", statistic="fisher")

#generate table of results
#kable(GenTable(over_functions_go_data, classic=over_resultsFisher_functions, topNodes=50))
#generate graph of results
#showSigOfNodes(over_functions_go_data, score(over_resultsFisher_functions), useInfo = "all")

#process GO analysis
overdegs_Process_GO<-readMappings("../Results/GOs/over_degs_p001_2LFC.processes.gos")
overback_Process_GO<-readMappings("../Results/GOs/Back_over_degs_p001_2LFC.processes.gos")

over_universe_for_process_topgo<-c(overdegs_Process_GO, overback_Process_GO)

#get names of genes in different groups
over_genes_of_interest_for_process<-names(overdegs_Process_GO)
over_genes_in_background_for_process<-names(overback_Process_GO)
over_genes_in_universe_for_process<-names(over_universe_for_process_topgo)

#get the list of genes of interest in the universe
over_genes_of_interest_list_for_process<-factor(as.integer(over_genes_in_universe_for_process %in% over_genes_of_interest_for_process))
names(over_genes_of_interest_list_for_process)<-over_genes_in_universe_for_process

#create a topGO object for Molecular Function
over_process_go_data<-new("topGOdata", ontology="BP", allGenes=over_genes_of_interest_list_for_process, annot=annFUN.gene2GO, gene2GO=over_universe_for_process_topgo)

#create a test object
over_resultsFisher_process<-runTest(over_process_go_data, algorithm = "classic", statistic="fisher")

#generate table of results
#kable(GenTable(over_process_go_data, classic=over_resultsFisher_process, topNodes=50))
#generate graph of results
#showSigOfNodes(over_process_go_data, score(over_resultsFisher_process), useInfo = "all")


#component GO analysis
overdegs_Component_GO<-readMappings("../Results/GOs/over_degs_p001_2LFC.components.gos")
overback_Component_GO<-readMappings("../Results/GOs/Back_over_degs_p001_2LFC.components.gos")

over_universe_for_component_topgo<-c(overdegs_Component_GO, overback_Component_GO)

#get names of genes in different groups
over_genes_of_interest_for_component<-names(overdegs_Component_GO)
over_genes_in_background_for_component<-names(overback_Component_GO)
over_genes_in_universe_for_component<-names(over_universe_for_component_topgo)

#get the list of genes of interest in the universe
over_genes_of_interest_list_for_component<-factor(as.integer(over_genes_in_universe_for_component %in% over_genes_of_interest_for_component))
names(over_genes_of_interest_list_for_component)<-over_genes_in_universe_for_component

#create a topGO object for Molecular Function
over_component_go_data<-new("topGOdata", ontology="CC", allGenes=over_genes_of_interest_list_for_component, annot=annFUN.gene2GO, gene2GO=over_universe_for_component_topgo)

#create a test object
over_resultsFisher_component<-runTest(over_component_go_data, algorithm = "classic", statistic="fisher")

#generate table of results
#kable(GenTable(over_component_go_data, classic=over_resultsFisher_component, topNodes=50))
#generate graph of results
#showSigOfNodes(over_component_go_data, score(over_resultsFisher_component), useInfo = "all")

```

Table 5: GO-Term functions overrepresented in the set of overexpressed DEGs.

```{r Generate_Over_GO_Function_analysis_table, echo=FALSE}
#generate table of results
kable(GenTable(over_functions_go_data, classic=over_resultsFisher_functions, topNodes=15))
```

Table 6: GO-Term processes overrepresented in the set of overexpressed DEGs.
```{r Generate_Over_GO_Process_analysis_table, echo=FALSE}
#generate table of results
kable(GenTable(over_process_go_data, classic=over_resultsFisher_process, topNodes=15))
```

Table 7: GO-Term compartments overrepresented in the set of overexpressed DEGs.
```{r Generate_Over_GO_Component_analysis_table, echo=FALSE}
#generate table of results
kable(GenTable(over_component_go_data, classic=over_resultsFisher_component, topNodes=15))
```

```{r Under_GO_analysis, include=FALSE, results='hide'}
#underexpressed genes only

#function GO analysis
underdegs_Function_GO<-readMappings("../Results/GOs/under_degs_p001_2LFC.functions.gos")
underback_Function_GO<-readMappings("../Results/GOs/Back_under_degs_p001_2LFC.functions.gos")

under_universe_for_function_topgo<-c(underdegs_Function_GO, underback_Function_GO)

#get names of genes in different groups
under_genes_of_interest_for_function<-names(underdegs_Function_GO)
under_genes_in_background_for_function<-names(underback_Function_GO)
under_genes_in_universe_for_function<-names(under_universe_for_function_topgo)

#get the list of genes of interest in the universe
under_genes_of_interest_list_for_function<-factor(as.integer(under_genes_in_universe_for_function %in% under_genes_of_interest_for_function))
names(under_genes_of_interest_list_for_function)<-under_genes_in_universe_for_function

#create a topGO object for Molecular Function
under_functions_go_data<-new("topGOdata", ontology="MF", allGenes=under_genes_of_interest_list_for_function, annot=annFUN.gene2GO, gene2GO=under_universe_for_function_topgo)

#create a test object
under_resultsFisher_functions<-runTest(under_functions_go_data, algorithm = "classic", statistic="fisher")

#generate table of results
#GenTable(under_functions_go_data, classic=under_resultsFisher_functions, topNodes=50)
#generate graph of results
#showSigOfNodes(under_functions_go_data, score(under_resultsFisher_functions), useInfo = "all")


#process GO analysis
underdegs_Process_GO<-readMappings("../Results/GOs/under_degs_p001_2LFC.processes.gos")
underback_Process_GO<-readMappings("../Results/GOs/Back_under_degs_p001_2LFC.processes.gos")

under_universe_for_process_topgo<-c(underdegs_Process_GO, underback_Process_GO)

#get names of genes in different groups
under_genes_of_interest_for_process<-names(underdegs_Process_GO)
under_genes_in_background_for_process<-names(underback_Process_GO)
under_genes_in_universe_for_process<-names(under_universe_for_process_topgo)

#get the list of genes of interest in the universe
under_genes_of_interest_list_for_process<-factor(as.integer(under_genes_in_universe_for_process %in% under_genes_of_interest_for_process))
names(under_genes_of_interest_list_for_process)<-under_genes_in_universe_for_process

#create a topGO object for Molecular Function
under_process_go_data<-new("topGOdata", ontology="BP", allGenes=under_genes_of_interest_list_for_process, annot=annFUN.gene2GO, gene2GO=under_universe_for_process_topgo)

#create a test object
under_resultsFisher_process<-runTest(under_process_go_data, algorithm = "classic", statistic="fisher")

#generate table of results
#GenTable(under_process_go_data, classic=under_resultsFisher_process, topNodes=50)
#generate graph of results
#showSigOfNodes(under_process_go_data, score(under_resultsFisher_process), useInfo = "all")


#component GO analysis
underdegs_Component_GO<-readMappings("../Results/GOs/under_degs_p001_2LFC.components.gos")
underback_Component_GO<-readMappings("../Results/GOs/Back_under_degs_p001_2LFC.components.gos")

under_universe_for_component_topgo<-c(underdegs_Component_GO, underback_Component_GO)

#get names of genes in different groups
under_genes_of_interest_for_component<-names(underdegs_Component_GO)
under_genes_in_background_for_component<-names(underback_Component_GO)
under_genes_in_universe_for_component<-names(under_universe_for_component_topgo)

#get the list of genes of interest in the universe
under_genes_of_interest_list_for_component<-factor(as.integer(under_genes_in_universe_for_component %in% under_genes_of_interest_for_component))
names(under_genes_of_interest_list_for_component)<-under_genes_in_universe_for_component

#create a topGO object for Molecular Function
under_component_go_data<-new("topGOdata", ontology="CC", allGenes=under_genes_of_interest_list_for_component, annot=annFUN.gene2GO, gene2GO=under_universe_for_component_topgo)

#create a test object
under_resultsFisher_component<-runTest(under_component_go_data, algorithm = "classic", statistic="fisher")

#generate table of results
#GenTable(under_component_go_data, classic=under_resultsFisher_component, topNodes=50)
#generate graph of results
#showSigOfNodes(under_component_go_data, score(under_resultsFisher_component), useInfo = "all")

```

Table 8: GO-Term functions overrepresented in the set of underexpressed DEGs.
```{r Generate_Under_GO_Function_analysis_table, echo=FALSE}
kable(GenTable(under_functions_go_data, classic=under_resultsFisher_functions, topNodes=15))
```

Table 9: GO-Term processes overrepresented in the set of underexpressed DEGs.
```{r Generate_Under_GO_Process_analysis_table, echo=FALSE}
kable(GenTable(under_process_go_data, classic=under_resultsFisher_process, topNodes=15))
```

Table 10: GO-Term compartments overrepresented in the set of underexpressed DEGs.
```{r Generate_Under_GO_Component_analysis_table, echo=FALSE}
kable(GenTable(under_component_go_data, classic=under_resultsFisher_component, topNodes=15))
```

##Pfam domains

Over

```{r Pfam_over_enrichment_analysis, echo=FALSE}

over_degs_pfam<-read.csv("../Results/Pfam/over_degs_p001_2LFC.pfam", sep="\t", head=F)
over_back_pfam<-read.csv("../Results/Pfam/Back_over_degs_p001_2LFC.pfam", sep = "\t", head=F)

over_domain_col<-c()
over_domain_in_degs_col<-c()
over_domain_in_back_col<-c()
over_domain_pval_col<-c()

over_count_in_degs<-nrow(over_degs_pfam)
over_count_in_back<-nrow(over_back_pfam)

over_domains<-read.csv("../Results/Pfam/over_degs_p001_2LFC.pfam.list", sep="\t", head=F)

for(over_domain in over_domains$V2){
  over_domain_count_in_degs<-nrow(over_degs_pfam[grep(over_domain, over_degs_pfam$V2),])
  over_domain_count_in_back<-nrow(over_back_pfam[grep(over_domain, over_back_pfam$V2),])

  over_domain_col<-c(over_domain_col,over_domain)
  over_domain_in_degs_col<-c(over_domain_in_degs_col, over_domain_count_in_degs)
  over_domain_in_back_col<-c(over_domain_in_back_col, over_domain_count_in_back)
  
  over_domain_pval_col<-c(over_domain_pval_col, phyper(over_domain_count_in_degs,over_domain_count_in_back,(over_count_in_back-over_domain_count_in_back),over_count_in_degs, lower.tail = F))
}

over_domain_pval_adjusted_col<-p.adjust(over_domain_pval_col, method="fdr")

over_pfam_domain_enrichment_df<-data.frame(over_domain_col, over_domain_in_degs_col, over_domain_in_back_col, over_domain_pval_col, over_domain_pval_adjusted_col)

colnames(over_pfam_domain_enrichment_df)<-c("Domain", "Count_in_DEGs", "Count_in_Background", "p_value", "Corrected_p_value")

selected_over_pfam_domain_enrichment_df<-subset(over_pfam_domain_enrichment_df, (Count_in_Background+Count_in_DEGs) > 5 & Corrected_p_value < 0.05)

selected_over_pfam_domain_enrichment_df<-selected_over_pfam_domain_enrichment_df[with(selected_over_pfam_domain_enrichment_df, order(Corrected_p_value)),]

kable(selected_over_pfam_domain_enrichment_df)

```

Under

```{r Pfam_under_enrichment_analysis, echo=FALSE}
#yes I know this code could be modularized better...

under_degs_pfam<-read.csv("../Results/Pfam/under_degs_p001_2LFC.pfam", sep="\t", head=F)
under_back_pfam<-read.csv("../Results/Pfam/Back_under_degs_p001_2LFC.pfam", sep = "\t", head=F)

under_domain_col<-c()
under_domain_in_degs_col<-c()
under_domain_in_back_col<-c()
under_domain_pval_col<-c()

under_count_in_degs<-nrow(under_degs_pfam)
under_count_in_back<-nrow(under_back_pfam)

under_domains<-read.csv("../Results/Pfam/under_degs_p001_2LFC.pfam.list", sep="\t", head=F)

for(under_domain in under_domains$V2){
  under_domain_count_in_degs<-nrow(under_degs_pfam[grep(under_domain, under_degs_pfam$V2),])
  under_domain_count_in_back<-nrow(under_back_pfam[grep(under_domain, under_back_pfam$V2),])

  under_domain_col<-c(under_domain_col,under_domain)
  under_domain_in_degs_col<-c(under_domain_in_degs_col, under_domain_count_in_degs)
  under_domain_in_back_col<-c(under_domain_in_back_col, under_domain_count_in_back)
  
  under_domain_pval_col<-c(under_domain_pval_col, phyper(under_domain_count_in_degs,under_domain_count_in_back,(under_count_in_back-under_domain_count_in_back),under_count_in_degs, lower.tail = F))
}

under_domain_pval_adjusted_col<-p.adjust(under_domain_pval_col, method="fdr")

under_pfam_domain_enrichment_df<-data.frame(under_domain_col, under_domain_in_degs_col, under_domain_in_back_col, under_domain_pval_col, under_domain_pval_adjusted_col)
colnames(under_pfam_domain_enrichment_df)<-c("Domain", "Count_in_DEGs", "Count_in_Background", "p_value", "Corrected_p_value")

selected_under_pfam_domain_enrichment_df<-subset(under_pfam_domain_enrichment_df, (Count_in_Background+Count_in_DEGs) > 5 & Corrected_p_value < 0.05)

selected_under_pfam_domain_enrichment_df<-selected_under_pfam_domain_enrichment_df[with(selected_under_pfam_domain_enrichment_df, order(Corrected_p_value)),]

kable(selected_under_pfam_domain_enrichment_df)
```


#Discussion


#Acknowledgements


###Conflict of interest

None declared.

###Author contributions

Sergio Vargas designed the study, conducted the experiments and analyzed the data. Gert Wörheide contributed reagents. Sergio Vargas and Gert Wörheide wrote the manuscript. Sergio Vargas manages the [project repository](https://github.com/sevragorgia/CBAS/).

###Disclaimer
None of the products or companies listed are endorsed or recommended in anyway by the author(s) of this text.

###Scripts and Data availability

All scripts used to analyze the data, as well as some miscellaneous scripts used to, for instance, prepare the annotation table or generate GO-term/Pfam input files for the enrichment analyses can be found in the [project repository](https://github.com/sevragorgia/CBAS/).

#References and Notes

[^1]: I have (repeatedly) failed to prepare libraries for Next Generation Sequencing from bleached tissue, probably due to the presence of secondary metabolites in the extracts.

[^2]: The 10 mm hole puncher has been replaced by a 6 mm version. [Click here to see the product.](http://www.sigmaaldrich.com/catalog/product/sigma/z708909?lang=de&region=DE)

[^3]: We, in fact, keep a permanent culture of "bleached" explants that are allowed to bleach for at least 12 weeks, are fixed in liquid nitrogen and stored at -80 °C.

[^4]: Zymo Research. [Click here to see the product website.](https://www.zymoresearch.de/rna/dna-rna-co-purification/cells-tissue-rna/zr-duet-dna-rna-miniprep)

[^5]: EMBL GeneCore. [http://genecore3.genecore.embl.de/genecore3/index.cfm](http://genecore3.genecore.embl.de/genecore3/index.cfm)

[^6]: FastQC. [http://www.bioinformatics.babraham.ac.uk/projects/fastqc/](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/)

[^7]: BioLite: [https://bitbucket.org/caseywdunn/biolite/overview](https://bitbucket.org/caseywdunn/biolite/overview)

[^8]: Downloaded early 2015. [Uniprot download.](http://www.uniprot.org/downloads)

[^9]: Aqu2 isoforms (proteins) [*Amphimedon queenslandica* transcriptome resource.](http://amphimedon.qcloud.qcif.edu.au/downloads.html)

[^10]: Blast was run from [Galaxy](https://galaxyproject.org/) and the XML file was converted to a 25 column table by the [ncbi_blast_plus](http://toolshed.g2.bx.psu.edu/view/devteam/ncbi_blast_plus) tool.

[^11]: Gene Ontology Consortium. [http://geneontology.org/](http://geneontology.org/)

[^12]: The UNIPROT accession code of the blast best match associated to each transcript in the CBAS transcriptome was used to query the GO annotations associated with the UNIPROT protein. These GO annotations were used to annotated the CBAS transcripts; note that these are annotations based on annotations and should be taken with precaution.

[^13]: TopGO [(https://bioconductor.org/packages/release/bioc/html/topGO.html)](https://bioconductor.org/packages/release/bioc/html/topGO.html) expects GO terms in tab separated {Trascript, GoAnnotation} pairs. The script produces output with a leading column indicating the UNIPROT accession code used for each transcript, which comes handy when controling the correct annotation was used for each transcript and can be easily removed for further analyses.

[^14]: Transdecoder's Github Repository can be found [here.](https://transdecoder.github.io/)

[^15]: I honestly do not know what the purpose of this blast run was, I did it for sake of completeness and because the reads were not filtered before assembling the conting. Yet, after seeing the results, it seems as if not too many contigs matched the bacterial database...

[^16]: Parra et al. 2007. CEGMA: a pipeline to accurately annotate core genes in eukaryotic genomes.  [Bioinformatics 23 (9): 1061-1067.](http://dx.doi.org/10.1093/bioinformatics/btm071)

[^17]: Francis et al. 2013. A comparison across non-model animals suggests an optimal sequencing depth for *de novo* transcriptome assembly. [BMC Genomics 14:167](http://dx.doi.org/10.1186/1471-2164-14-167)

[^18]: the script is also provided as part of this repository. The Copyright (c) of this script belongs trinityrnaseq (2014), who reserves all rights upon the code. [See the full LICENSE here.](https://github.com/trinityrnaseq/trinityrnaseq/blob/master/LICENSE)

[^19]: With these graphs were produced for transcripts that could be successfully translated using **Transdecoder**. In the case of the **Uniprot** and **Aqu2** annotations, the transcripts were directly blasted using blastn. Thus could be possible to obtain **Uniprot** and **Aqu2** annotations for transcripts that could not be translated with **Transdecoder**. This is in fact the case, however the number of transcripts that could not *transdecoded* but were annotated is relatively small. In the case of **Uniprot**, the number of transcripts that yielded annotations but were not *transdecoded* was **`r as.vector(table(!is.na(meta_annotations$Protein), !is.na(meta_annotations$Uniprot_match)))[3]`**. For **Aqu2**, only **`r as.vector(table(!is.na(meta_annotations$Protein), !is.na(meta_annotations$Aqu2_match)))[3]`** not *transdecoded* transcripts could be annotated.

[^20]: Here it is worth noting that the evalue cutoff used for blast against the Uniprot and Aqu2 databases was 0.001. So the annotations obtained had an evalue at least two orders of magnitud smaller than the set cutoff evalue.


